---
title: "Project proposal"
author: "Team Weather- Colin, Kailor & Jennifer"
output: github_document
---

```{r load-packages, message = FALSE}
library(tidyverse)
library(broom)
library(lubridate)
```

## 1. Introduction

The introduction should introduce your general research question(s) and your data (where it came from, how it was collected, what are the cases, what are the variables, etc.).

Our general research question is: Has the number of extreme weather events in the U.S. increased from 2010-2020?

We will achieve this by simply focusing on whether the quantity of extreme weather events in general has increased or if certain types of extreme weather events have increased or decreased over the decade. We can also focus on severity and if the severity of each extreme weather event has on average increased or decreased. 

Our data comes from NOAA (National Oceanic and Atmospheric Administration) and is collected by various sources such as, trained spotters, social media, 911 call centers, fire departments, law enforcement, NWS (National weather service) employees, Newspapers, and public reports. 

extreme weather examples: ("Avalanche","Blizzard","Drought","Flood","Flash Flood","Excessive Heat","Tornado","Tropical Storm","Tsunami","Wildfire"

A full breakdown of each column is in the codebook, data/readme.md

Refer to the Markdown Quick Reference: Help -> Markdown Quick Reference. 


## 2. Data
Here, we filter out observations not needed, and remove unncessary columns.
```{r 2010, eval=FALSE}
StormEvents_2010 <- read_csv("../data/ignore/StormEvents_details-ftp_v1.0_d2010_c20250520.csv")
FiltStormEvents2010 <- StormEvents_2010|>
  filter(EVENT_TYPE %in% c("Avalanche","Blizzard","Drought","Flood","Flash Flood","Excessive Heat","Tornado","Tropical Storm","Tsunami","Wildfire"))

FiltStormEvents2010 <- FiltStormEvents2010 |>
  select(-STATE_FIPS,-CZ_TYPE,-CZ_FIPS,-CZ_NAME,-TOR_F_SCALE, -TOR_LENGTH,-TOR_WIDTH,-TOR_OTHER_WFO,-TOR_OTHER_CZ_STATE,-TOR_OTHER_CZ_FIPS,-TOR_OTHER_CZ_NAME,-BEGIN_RANGE,-BEGIN_AZIMUTH,-BEGIN_LOCATION,-END_RANGE,-END_AZIMUTH,-END_LOCATION,-EPISODE_NARRATIVE,-EVENT_NARRATIVE,-DATA_SOURCE,-WFO,-YEAR)
glimpse(FiltStormEvents2010)
```

```{r 2011, eval=FALSE}
StormEvents_2011 <- read_csv("../data/ignore/StormEvents_details-ftp_v1.0_d2011_c20250520.csv")
FiltStormEvents2011 <- StormEvents_2011|>
  filter(EVENT_TYPE %in% c("Avalanche","Blizzard","Drought","Flood","Flash Flood","Excessive Heat","Tornado","Tropical Storm","Tsunami","Wildfire"))

FiltStormEvents2011 <- FiltStormEvents2011 |>
  select(-STATE_FIPS,-CZ_TYPE,-CZ_FIPS,-CZ_NAME,-TOR_F_SCALE, -TOR_LENGTH,-TOR_WIDTH,-TOR_OTHER_WFO,-TOR_OTHER_CZ_STATE,-TOR_OTHER_CZ_FIPS,-TOR_OTHER_CZ_NAME,-BEGIN_RANGE,-BEGIN_AZIMUTH,-BEGIN_LOCATION,-END_RANGE,-END_AZIMUTH,-END_LOCATION,-EPISODE_NARRATIVE,-EVENT_NARRATIVE,-DATA_SOURCE,-WFO,-YEAR)
glimpse(FiltStormEvents2011)
```

```{r 2012, eval=FALSE}
StormEvents_2012 <- read_csv("../data/ignore/StormEvents_details-ftp_v1.0_d2012_c20250520.csv")

FiltStormEvents2012 <- StormEvents_2012|>
  filter(EVENT_TYPE %in% c("Avalanche","Blizzard","Drought","Flood","Flash Flood","Excessive Heat","Tornado","Tropical Storm","Tsunami","Wildfire"))

FiltStormEvents2012 <- FiltStormEvents2012 |>
  select(-STATE_FIPS,-CZ_TYPE,-CZ_FIPS,-CZ_NAME,-TOR_F_SCALE, -TOR_LENGTH,-TOR_WIDTH,-TOR_OTHER_WFO,-TOR_OTHER_CZ_STATE,-TOR_OTHER_CZ_FIPS,-TOR_OTHER_CZ_NAME,-BEGIN_RANGE,-BEGIN_AZIMUTH,-BEGIN_LOCATION,-END_RANGE,-END_AZIMUTH,-END_LOCATION,-EPISODE_NARRATIVE,-EVENT_NARRATIVE,-DATA_SOURCE,-WFO,-YEAR)
glimpse(FiltStormEvents2012)
```

```{r 2013, eval=FALSE}
StormEvents_2013 <- read_csv("../data/ignore/StormEvents_details-ftp_v1.0_d2013_c20250520.csv")

FiltStormEvents2013 <- StormEvents_2013|>
  filter(EVENT_TYPE %in% c("Avalanche","Blizzard","Drought","Flood","Flash Flood","Excessive Heat","Tornado","Tropical Storm","Tsunami","Wildfire"))

FiltStormEvents2013 <- FiltStormEvents2013 |>
  select(-STATE_FIPS,-CZ_TYPE,-CZ_FIPS,-CZ_NAME,-TOR_F_SCALE, -TOR_LENGTH,-TOR_WIDTH,-TOR_OTHER_WFO,-TOR_OTHER_CZ_STATE,-TOR_OTHER_CZ_FIPS,-TOR_OTHER_CZ_NAME,-BEGIN_RANGE,-BEGIN_AZIMUTH,-BEGIN_LOCATION,-END_RANGE,-END_AZIMUTH,-END_LOCATION,-EPISODE_NARRATIVE,-EVENT_NARRATIVE,-DATA_SOURCE,-WFO,-YEAR)
glimpse(FiltStormEvents2013)
```

```{r 2014, eval=FALSE}
StormEvents_2014 <- read_csv("../data/ignore/StormEvents_details-ftp_v1.0_d2014_c20250520.csv")

FiltStormEvents2014 <- StormEvents_2014|>
  filter(EVENT_TYPE %in% c("Avalanche","Blizzard","Drought","Flood","Flash Flood","Excessive Heat","Tornado","Tropical Storm","Tsunami","Wildfire"))

FiltStormEvents2014 <- FiltStormEvents2014 |>
  select(-STATE_FIPS,-CZ_TYPE,-CZ_FIPS,-CZ_NAME,-TOR_F_SCALE, -TOR_LENGTH,-TOR_WIDTH,-TOR_OTHER_WFO,-TOR_OTHER_CZ_STATE,-TOR_OTHER_CZ_FIPS,-TOR_OTHER_CZ_NAME,-BEGIN_RANGE,-BEGIN_AZIMUTH,-BEGIN_LOCATION,-END_RANGE,-END_AZIMUTH,-END_LOCATION,-EPISODE_NARRATIVE,-EVENT_NARRATIVE,-DATA_SOURCE,-WFO,-YEAR)
glimpse(FiltStormEvents2014)
```

```{r 2015, eval=FALSE}
StormEvents_2015 <- read_csv("../data/ignore/StormEvents_details-ftp_v1.0_d2015_c20250818.csv")

FiltStormEvents2015 <- StormEvents_2015|>
  filter(EVENT_TYPE %in% c("Avalanche","Blizzard","Drought","Flood","Flash Flood","Excessive Heat","Tornado","Tropical Storm","Tsunami","Wildfire"))

FiltStormEvents2015 <- FiltStormEvents2015 |>
  select(-STATE_FIPS,-CZ_TYPE,-CZ_FIPS,-CZ_NAME,-TOR_F_SCALE, -TOR_LENGTH,-TOR_WIDTH,-TOR_OTHER_WFO,-TOR_OTHER_CZ_STATE,-TOR_OTHER_CZ_FIPS,-TOR_OTHER_CZ_NAME,-BEGIN_RANGE,-BEGIN_AZIMUTH,-BEGIN_LOCATION,-END_RANGE,-END_AZIMUTH,-END_LOCATION,-EPISODE_NARRATIVE,-EVENT_NARRATIVE,-DATA_SOURCE,-WFO,-YEAR)
glimpse(FiltStormEvents2015)
```

```{r 2016, eval=FALSE}
StormEvents_2016 <- read_csv("../data/ignore/StormEvents_details-ftp_v1.0_d2016_c20250818.csv")

FiltStormEvents2016 <- StormEvents_2016|>
  filter(EVENT_TYPE %in% c("Avalanche","Blizzard","Drought","Flood","Flash Flood","Excessive Heat","Tornado","Tropical Storm","Tsunami","Wildfire"))

FiltStormEvents2016 <- FiltStormEvents2016 |>
  select(-STATE_FIPS,-CZ_TYPE,-CZ_FIPS,-CZ_NAME,-TOR_F_SCALE, -TOR_LENGTH,-TOR_WIDTH,-TOR_OTHER_WFO,-TOR_OTHER_CZ_STATE,-TOR_OTHER_CZ_FIPS,-TOR_OTHER_CZ_NAME,-BEGIN_RANGE,-BEGIN_AZIMUTH,-BEGIN_LOCATION,-END_RANGE,-END_AZIMUTH,-END_LOCATION,-EPISODE_NARRATIVE,-EVENT_NARRATIVE,-DATA_SOURCE,-WFO,-YEAR)
glimpse(FiltStormEvents2016)
```

```{r 2017, eval=FALSE}
StormEvents_2017 <- read_csv("../data/ignore/StormEvents_details-ftp_v1.0_d2017_c20250520.csv")

FiltStormEvents2017 <- StormEvents_2017|>
  filter(EVENT_TYPE %in% c("Avalanche","Blizzard","Drought","Flood","Flash Flood","Excessive Heat","Tornado","Tropical Storm","Tsunami","Wildfire"))

FiltStormEvents2017 <- FiltStormEvents2017 |>
  select(-STATE_FIPS,-CZ_TYPE,-CZ_FIPS,-CZ_NAME,-TOR_F_SCALE, -TOR_LENGTH,-TOR_WIDTH,-TOR_OTHER_WFO,-TOR_OTHER_CZ_STATE,-TOR_OTHER_CZ_FIPS,-TOR_OTHER_CZ_NAME,-BEGIN_RANGE,-BEGIN_AZIMUTH,-BEGIN_LOCATION,-END_RANGE,-END_AZIMUTH,-END_LOCATION,-EPISODE_NARRATIVE,-EVENT_NARRATIVE,-DATA_SOURCE,-WFO,-YEAR)
glimpse(FiltStormEvents2017)
```

```{r 2018, eval=FALSE}
StormEvents_2018 <- read_csv("../data/ignore/StormEvents_details-ftp_v1.0_d2018_c20250520.csv")

FiltStormEvents2018 <- StormEvents_2018|>
  filter(EVENT_TYPE %in% c("Avalanche","Blizzard","Drought","Flood","Flash Flood","Excessive Heat","Tornado","Tropical Storm","Tsunami","Wildfire"))

FiltStormEvents2018 <- FiltStormEvents2018 |>
  select(-STATE_FIPS,-CZ_TYPE,-CZ_FIPS,-CZ_NAME,-TOR_F_SCALE, -TOR_LENGTH,-TOR_WIDTH,-TOR_OTHER_WFO,-TOR_OTHER_CZ_STATE,-TOR_OTHER_CZ_FIPS,-TOR_OTHER_CZ_NAME,-BEGIN_RANGE,-BEGIN_AZIMUTH,-BEGIN_LOCATION,-END_RANGE,-END_AZIMUTH,-END_LOCATION,-EPISODE_NARRATIVE,-EVENT_NARRATIVE,-DATA_SOURCE,-WFO,-YEAR)
glimpse(FiltStormEvents2018)
```

```{r 2019, eval=FALSE}
StormEvents_2019 <- read_csv("../data/ignore/StormEvents_details-ftp_v1.0_d2019_c20250520.csv")

FiltStormEvents2019 <- StormEvents_2019|>
  filter(EVENT_TYPE %in% c("Avalanche","Blizzard","Drought","Flood","Flash Flood","Excessive Heat","Tornado","Tropical Storm","Tsunami","Wildfire"))

FiltStormEvents2019 <- FiltStormEvents2019|>
  select(-STATE_FIPS,-CZ_TYPE,-CZ_FIPS,-CZ_NAME,-TOR_F_SCALE, -TOR_LENGTH,-TOR_WIDTH,-TOR_OTHER_WFO,-TOR_OTHER_CZ_STATE,-TOR_OTHER_CZ_FIPS,-TOR_OTHER_CZ_NAME,-BEGIN_RANGE,-BEGIN_AZIMUTH,-BEGIN_LOCATION,-END_RANGE,-END_AZIMUTH,-END_LOCATION,-EPISODE_NARRATIVE,-EVENT_NARRATIVE,-DATA_SOURCE,-WFO,-YEAR)
glimpse(FiltStormEvents2019)
```

```{r 2020, eval=FALSE}
StormEvents_2020 <- read_csv("../data/ignore/StormEvents_details-ftp_v1.0_d2020_c20250702.csv")

FiltStormEvents2020 <- StormEvents_2020|>
  filter(EVENT_TYPE %in% c("Avalanche","Blizzard","Drought","Flood","Flash Flood","Excessive Heat","Tornado","Tropical Storm","Tsunami","Wildfire"))

FiltStormEvents2020 <- FiltStormEvents2020|>
  select(-STATE_FIPS,-CZ_TYPE,-CZ_FIPS,-CZ_NAME,-TOR_F_SCALE, -TOR_LENGTH,-TOR_WIDTH,-TOR_OTHER_WFO,-TOR_OTHER_CZ_STATE,-TOR_OTHER_CZ_FIPS,-TOR_OTHER_CZ_NAME,-BEGIN_RANGE,-BEGIN_AZIMUTH,-BEGIN_LOCATION,-END_RANGE,-END_AZIMUTH,-END_LOCATION,-EPISODE_NARRATIVE,-EVENT_NARRATIVE,-DATA_SOURCE,-WFO,-YEAR)
glimpse(FiltStormEvents2020)
```

```{r bind_dfs, eval=FALSE}
storms <- rbind(FiltStormEvents2010,
                FiltStormEvents2011,
                FiltStormEvents2012,
                FiltStormEvents2013,
                FiltStormEvents2014,
                FiltStormEvents2015,
                FiltStormEvents2016,
                FiltStormEvents2017,
                FiltStormEvents2018,
                FiltStormEvents2019,
                FiltStormEvents2020)
write_csv(storms, file="../data/storms.csv")
```
```{r loadCSV}
# reload CSV because above chunks are eval=FALSE to avoid crashing Posit.
storms <- read_csv("../data/storms.csv")
```

The combined storms dataset has `r nrow(storms)` rows and `r ncol(storms)` columns.

## 3. Data analysis plan

Text goes here.
- What variables will you visualize to explore your research questions?

- Will there be any other data that you need to find to help with your research question?

- Very preliminary exploratory data analysis, including some summary statistics and visualizations, along with some explanation on how they help you learn more about your data. (You can add to these later as you work on your project.)

- The data visualization(s) that you believe will be useful in exploring your question(s). (You can update these later as you work on your project.)

### Preliminary visualization examples + summary statistics

Data Cleaning
```{r data_cleanup}
storms <- storms|>
  separate(
    col = BEGIN_YEARMONTH,
    into = c("BEGIN_YEAR", "BEGIN_MONTH"),
    sep = 4,
    convert = TRUE
  )
```

```{r change_date_format}
storms <- storms|>
  mutate(BEGIN_DATE = as_date(BEGIN_DATE_TIME))
```

<<<<<<< HEAD
=======
```{r dimensions}
dim(storms)
```
The combined storms dataset has `r nrow(storms)` rows and `r ncol(storms)` columns.


>>>>>>> 9440c8966517093217c33e3e5ffd772d96819ec5
```{r glimpse}
glimpse(storms)
```

<<<<<<< HEAD
Visualizations
=======


## 3. Data analysis plan

The variables we will be visualizing to explore our research questions include:
1. `BEGIN_YEAR` and `EVENT_TYPE` — to examine whether the total number of storm events has increased from 2010 to 2020. Other type of events are also in consider.
2. `STATE` and `EVENT_TYPE` — to identify the differences in storm frequency or type distribution over time across states.
3. `BEGIN_YEAR` and `DAMAGE_PROPERTY` — to indicate the severity or financial impact events has evolved.

Other data needed:
- Regional climate for exploring correlation with event frequency.

Types of graphs we may want to use: 
- Stacked bar charts – to show the distribution of `EVENT_TYPE` by `BEGIN_YEAR`.
- Facet plots – to visualize trends of each event type seperately.
- Boxplots – to compare the distributions of `DAMAGE_PROPERTY` and `INJURIES_DIRECT` by event type.
- Scatterplots with trend lines – to show relationships between year and severity.

>>>>>>> 9440c8966517093217c33e3e5ffd772d96819ec5

```{r total_storm_events}
storms|>
  ggplot(aes(x=BEGIN_YEAR, fill=EVENT_TYPE))+
  geom_bar() +
  labs(
    title = "Total number of storm events per year",
    subtitle = "From 2010-2020",
    x = "Year",
    y = "Count",
    fill = "Storm type"
  )
```

```{r storm_by_type}
storms|>
  ggplot(aes(x=BEGIN_YEAR))+
  geom_bar() +
  facet_wrap(~EVENT_TYPE, ncol=4) +
  labs(
    title = "Total number of storm events per year",
    subtitle = "From 2010-2020",
    x = "Year",
    y = "Count"
  )
```

